Perhaps more interesting than measures of tree imbalance is the way cover trees
are actually used in dual-tree algorithms.  Although cover trees were originally
intended for nearest neighbor search \citep*[see Algorithm
\texttt{Find-All-Nearest},][]{langford2006}, they can be adapted to a wide
variety of problems: minimum
spanning tree calculation \citep{march2010euclidean}, approximate nearest neighbor
search \citep{ram2009rank}, Gaussian processes posterior calculation
\citep{moore2014fast}, max-kernel search \citep{curtin2014dual} are some
examples.  Further, through the tree-independent dual-tree algorithm abstraction
of \citet{curtin2013tree}, other existing dual-tree algorithms can easily be
adapted for use with cover trees.

In the framework of tree-independent dual-tree algorithms, all that is necessary
to describe a dual-tree algorithm is a point-to-point base case function
(\texttt{BaseCase()}) and a node-to-node pruning rule (\texttt{Score()}).  These
functions, which are often very straightforward, are then paired with a type of
tree and a pruning dual-tree traversal to produce a working algorithm.  In later
sections, we will consider specific examples.

\begin{algorithm}[tb]
  \begin{algorithmic}[1]
    \STATE {\bfseries Input:} query node $\mathscr{N}_q$, set of reference nodes
$R$ \label{alg:line:ct-dual-input}
    \STATE {\bfseries Output:} none

    \medskip
    \STATE $s^{\max}_r \gets \max_{\mathscr{N}_r \in R} s_r$
    \IF{$(s_q < s^{\max}_r)$ {\bf or} $(s^{\max}_r = -\infty)$}
\label{alg:line:ct-dual-ref-recursion-start}
      \FORALL{$\mathscr{N}_r \in R$} \label{alg:line:ct-dual-base-case-start}
        \STATE \texttt{BaseCase($p_q$, $p_r$)}
      \ENDFOR \label{alg:line:ct-dual-base-case-end}
      \STATE $R_r \gets \{ \mathscr{N}_r \in R : s_r = s^{\max}_r \}$
\label{alg:line:ct-dual-ref-set}
      \STATE $R_{r - 1} \gets \{ \mathscr{C}(\mathscr{N}_r) : \mathscr{N}_r \in
R_r \} \cup (R \setminus R_r)$ \label{alg:line:ct-dual-ref-children}
      \STATE $R'_{r - 1} \gets \{ \mathscr{N}_r \in R_{r - 1} :
\texttt{Score(}\mathscr{N}_q\texttt{,} \mathscr{N}_r\texttt{)} \ne \infty \}$
\label{alg:line:ct-dual-ref-score}
      \STATE recurse with $\mathscr{N}_q$ and $R'_{r - 1}$
\label{alg:line:ct-dual-ref-recursion-end}
    \ELSE \label{alg:line:ct-dual-query-recursion-start}
      \FORALL{$\mathscr{N}_{qc} \in \mathscr{C}(\mathscr{N}_q)$}
        \STATE $R' \gets \{ \mathscr{N}_r \in R :
\texttt{Score(}\mathscr{N}_q\texttt{,} \mathscr{N}_r\texttt{)} \ne \infty \}$
\label{alg:line:ct-dual-query-pruning}
        \STATE recurse with $\mathscr{N}_{qc}$ and $R'$
\label{alg:line:ct-dual-query-recursion}
      \ENDFOR \label{alg:line:ct-dual-query-recursion-end}
    \ENDIF
  \end{algorithmic}
  \caption{The standard pruning dual-tree traversal for cover trees.}
  \label{alg:cover-tree-dual}
\end{algorithm}

When using cover trees, the typical pruning dual-tree traversal is an adapted
form of the original nearest neighbor search algorithm \citep[see
\texttt{Find-All-Nearest},][]{langford2006}; this traversal is implemented in
both the cover tree reference implementation and in the more flexible {\bf
mlpack} library \citep{mlpack2013}.  The algorithm is given in Algorithm
\ref{alg:cover-tree-dual} and was originally presented by
\citet{curtin2014dual}.  Initially, it is called with the root of the query tree
and a reference set containing only the root of the reference tree.

This dual-tree recursion is a depth-first recursion in the query tree and a
breadth-first recursion in the reference tree.  It descends either the query
tree or the reference tree (not both) during a single iteration, and the
conditional in line \ref{alg:line:ct-dual-ref-recursion-start} ensures that the
combinations of query and reference nodes that are being visited are close in
scale.

Due to the favorable theoretical properties of the cover tree, we can prove
general runtime bounds when this traversal is used.

\begin{thm}
\label{thm:ct-runtime}
%For any dual-tree algorithm using cover trees and the standard cover tree
%dual-tree pruning traversal (Algorithm \ref{alg:cover-tree-dual}) with reference
%set $S_r$ that has expansion constant $c_r$ and query set $S_q$, the runtime is
%bounded above by $O(c_r^4 | R^* | \nu \chi \psi N)$, where $ | R^* | $ is
%the maximum size of the reference set $R$ (line
%\ref{alg:line:ct-dual-input}) at any point in the dual-tree pruning traversal,
%$\chi$ is the longest possible running time of \texttt{BaseCase()}, and $\psi$
%is the longest possible running time of \texttt{Score()}.
Given a reference set $S_r$ of size $N$ with an expansion constant $c_r$ and a
set of queries $S_q$ of size $O(N)$, a standard cover tree based dual-tree
algorithm (Algorithm \ref{alg:cover-tree-dual}) takes

\begin{equation}
O\left(c_r^4 | R^* | \chi \psi (N + \theta)\right)
\end{equation}

\noindent time, where $ | R^* | $ is the maximum size of the reference set $R$
(line \ref{alg:line:ct-dual-input}) during the dual-tree recursion, $\chi$ is
the maximum possible runtime of \texttt{BaseCase()}, $\psi$ is the maximum
possible runtime of \texttt{Score()}, and $\theta$ is a measure of imbalance
defined by

\begin{equation}
\theta = \max(\log_2(\eta_r / \eta_q), 0) + i_t(\mathscr{T}_q) + N
\max(\log_2(\delta_q / \delta_r), 0)
\end{equation}

\noindent with $\eta_q$ as the maximum pairwise distance between points in
$S_q$, $\delta_q$ as the minimum nonzero pairwise distance between points in
$S_q$, $\eta_r$ as the maximum pairwise distance between points in $S_r$, and
$\delta_r$ as the minimum nonzero pairwise distance between points in $S_r$.
\end{thm}

\begin{proof}
First, split the algorithm into two parts: reference recursions (lines
\ref{alg:line:ct-dual-ref-recursion-start}--\ref{alg:line:ct-dual-ref-recursion-end})
and query recursions (lines
\ref{alg:line:ct-dual-query-recursion-start}--\ref{alg:line:ct-dual-query-recursion-end}).
The runtime of the algorithm is bounded as the runtime of a reference recursion
times the total number of reference recursions plus the total runtime of all
query recursions.

Consider a reference recursion (lines
\ref{alg:line:ct-dual-ref-recursion-start}--\ref{alg:line:ct-dual-ref-recursion-end}).
The work done in the base case loop from lines
\ref{alg:line:ct-dual-base-case-start}--\ref{alg:line:ct-dual-base-case-end} is
$O(\chi | R |)$.  Define $| R^* |$ to be the largest set $|R|$ for any scale
$s_r^{\max}$ and any query node $\mathscr{N}_q$ during the course of the
algorithm; then, it is true that $| R | \le | R^* |$.
%
Then, lines \ref{alg:line:ct-dual-ref-children} and
\ref{alg:line:ct-dual-ref-score} take $O(c_r^4 \psi | R |) \le O(c_r^4 \psi |
R^* |)$ time, because each reference node has $c_r^4$ children.  So, one
full reference recursion takes $O(c_r^4 \psi \chi | R^* |)$ time.

Now, note that there are $O(N)$ nodes in $\mathscr{T}_q$.  Thus, line
\ref{alg:line:ct-dual-query-recursion} is visited $O(N)$ times.  The amount of
work in line \ref{alg:line:ct-dual-query-pruning}, like in the reference
recursion, is bounded as $O(c_r^4 \psi | R^* |)$. Therefore, the total
runtime of all query recursions is $O(c_r^4 \psi | R^* | N)$.

Lastly, we must bound the total number of reference recursions.  Reference
recursions happen in three cases: \textit{(1)} $s_r^{\max}$ is greater than the
scale of the root of the query tree (no query recursions have happened yet);
\textit{(2)} $s_r^{\max}$ is less than or equal to the scale of the root of the
query tree, but is greater than the minimum scale of the query tree that is not
$-\infty$; \textit{(3)} $s_r^{\max}$ is less than the minimum scale of the query
tree that is not $-\infty$.

First, consider case \textit{(1)}.  If the scale of the root of the query tree
is $s_q^T$ and the scale of the root of the reference tree is $s_r^T$, then
$s_r^T - s_q^T$ recursions of this sort occur before the first query recursion.

Next, consider case \textit{(2)}.  In this situation, each query recursion
implies at least one reference recursion before another query recursion.  For
some query node $\mathscr{N}_q$, the
exact number of reference recursions before the children of $\mathscr{N}_q$ are
recursed into is bounded above by $i_t(\mathscr{N}_q) + 1$: if $\mathscr{N}_q$ has
imbalance $0$, then it is exactly one level below its parent, and thus there is
only one reference recursion.  On the other hand, if $\mathscr{N}_q$ is many
levels below its parent, then it is possible that a reference recursion may
occur for each level in between; this is a maximum of $i_t(\mathscr{N}_q) + 1$.

Because each query node in $\mathscr{T}_q$ is recursed into once, the total
number of reference recursions before each query recursion is

\begin{equation}
\sum_{\mathscr{N}_q \in \mathscr{T}_q} i_t(\mathscr{N}_q) + 1 = b(\mathscr{T}_q) +
O(N)
\end{equation}

\noindent since there are $O(N)$ nodes in the query tree.

Lastly, case \textit{(3)} occurs when the reference scale is less than the
minimum query scale $s_q^{\min}$; that is, all of the query recursions are done.
Define the minimum reference scale as $s_r^{\min}$.  If $s_q^{\min} - s_r^{\min}
> 0$, each query node may have up to $s_q^{\min} - s_r^{\min}$ reference
recursions of type \textit{(3)}, and there are $O(N)$ query nodes.  Thus, the
total number of reference recursions of type \textit{(3)} is bounded by $O(N)
\max(s_q^{\min} - s_r^{\min}, 0)$.

Combining these three cases, we get the following expression for an upper bound
$\theta$ on the total number of reference recursions:

\begin{equation}
\theta = \max(s_r^T - s_q^T, 0) + b(\mathscr{T}_q) + O(N) + O(N) (s_q^{\min} -
s_r^{\min}).
\end{equation}

Now, we can express these in terms of more common constants which are related to
the aspect ratio of the data.  Define $\delta_q$ as the minimum nonzero pairwise
distance in $S_q$ and $\eta_q$ as the furthest pairwise distance in $S_q$ (and
define $\delta_r$ and $\eta_r$ accordingly for the set $S_r$).  Then, $s_r^T =
\lceil \log_2 \eta_r \rceil$, $s_q^T = \lceil \log_2 \eta_q \rceil$, $s_r^{\min}
= \lceil \log_2 \delta_r \rceil$, and $s_q^{\min} = \lceil \log_2 \delta_q
\rceil$.  This gives a more reasonable expression:

\begin{equation}
\theta = \max\left(\log_2\left(\frac{\eta_r}{\eta_q}\right), 0\right) +
b(\mathscr{T}_q) + O(N) + O(N)
\max\left(\log_2\left(\frac{\delta_q}{\delta_r}\right), 0\right).
\end{equation}

Returning to our original line of reasoning, we can combine these results to
give the result of the theorem:

\begin{equation}
O(c_r^4 \psi \chi | R^* | \theta) + O(c_r^4 \psi | R^* | N) \sim O(c_r^4 \psi
\chi |R^*| (N + \theta)).
\end{equation}
\end{proof}

When we consider the monochromatic case (where $S_q = S_r$), the results
trivially simplify.

\begin{cor}
\label{cor:ct-runtime-mono}
Given the situation of Theorem \ref{thm:ct-runtime} but with $S_q = S_r = S$ so
that $c_q = c_r = c$ and $\mathscr{T}_q = \mathscr{T}_r = \mathscr{T}$, a
standard cover tree based dual-tree algorithm (Algorithm
\ref{alg:cover-tree-dual}) takes

\begin{equation}
O\left(c^4 |R^*| \chi \psi (N + i_t(\mathscr{T}))\right)
\end{equation}

\noindent time, where $ | R^* | $ is the maximum size of the reference set $R$
(line \ref{alg:line:ct-dual-input}) during the dual-tree recursion, $\chi$ is
the maximum possible runtime of \texttt{BaseCase()}, and $\psi$ is the maximum
possible runtime of \texttt{Score()}.
\end{cor}

An intuitive understanding of these bounds is best achieved by first considering
the monochromatic case (this case arises, for instance, in all-nearest-neighbor
search).  The linear dependence on $N$ arises from the fact that all query nodes
must be visited.  The dependence on the reference tree, however, is encapsulated
by the term $c^4 |R^*|$, with $|R^*|$ being the maximum size of the reference
set $R$; this value must be derived for each specific problem.  The bad
performance of poorly-behaved datasets with large $c$ (or, in the worst case, $c
\sim N$) is then captured in both of those terms.  Poorly-behaved datasets may
also have a high cover tree imbalance $i_t(\mathscr{T})$; the linear dependence of
runtime on imbalance is thus sensible.

The bichromatic case ($S_q \ne S_r$) is a slightly more complex result which
deserves a bit more attention.  The intuition for all terms except $\theta$
remain virtually the same, although it is worth pointing out that there is
no dependence on the reference set size.

The term $\theta$ captures the effect of query and reference datasets with
different widths, and has two corner cases: all extra reference recursions are of
type \textit{(1)}, and all extra reference recursions are of type \textit{(3)}.
The first case presents the best situation, because all of the reference
recursions are done before the first query node is recursed into\footnote{In
fact, re-derivation for this specific case can remove the dependence on
$i_t(\mathscr{T}_q)$ entirely.  But our bound, as derived, does not bound this
behavior tightly.  To do so would introduce a number of complex constants, and
thus in that respect $i_t(\mathscr{T}_q)$ is a more suitable bounding quantity}.
Therefore the bulk of the reference recursion work is done by with the query
tree root as the query node; this is the best case.  The worst case is the
latter, where recursion in the reference tree cannot begin until reaching the
bottom of the query tree.  Thus, no pruning can occur until reaching the leaves
of the query tree, and the recursion is essentially equivalent to a single-tree
recursion for each query point plus the added overhead of the recursion of the
query tree with one reference node.

{\bf TODO: what does the second case degenerate to in terms of running time?}

The quantity $|R^*|$ bounds the amount of work that needs to be done for each
recursion. In the worst case, $|R^*|$ can be $N$. However,
dual-tree algorithms rely on branch-and-bound techniques to prune away
work (Lines \ref{alg:line:ct-dual-ref-score} and
\ref{alg:line:ct-dual-query-pruning} in Algorithm \ref{alg:cover-tree-dual}). A
small value of $|R^*|$ will imply that the algorithm is extremely successful in
pruning away work at Line \ref{alg:line:ct-dual-ref-score} in Algorithm
\ref{alg:cover-tree-dual}. An (upper) bound on $|R^*|$ (and the algorithm's
success in pruning work) will depend on the problem and the data.  As we will
show, bounding $|R^*|$ is often possible. % In addition, we will also show that
For many dual-tree algorithms, $\chi \sim \psi \sim O(1)$; often, cached
sufficient statistics \citep{moore2000anchors} can enable $O(1)$ runtime
implementations of \texttt{BaseCase()} and \texttt{Score()}.

These results hold for any dual-tree algorithm regardless of the problem. Hence,
%for any pairwise statistical problem, the runtime of the dual-tree algorithm (of
the runtime of any dual-tree algorithm
%that problem)
would be at least $O(N)$ using our bound, which matches the intuition that
answering $O(N)$ queries would take at least $O(N)$ time. For a particular
problem and data, if $c_r$, $|R^*|$, $\chi$, $\psi$ are bounded by constants
independent of $N$ and $\theta$ is no more than linear in $N$ (for large enough
$N$), then the dual-tree algorithm for that problem has a runtime linear in $N$.
Our theoretical result separates out the problem-dependent and the
problem-independent elements of the runtime bound, which allows us to simply
plug in the problem-dependent bounds to get runtime bounds for any dual-tree
algorithm without requiring an analysis from scratch.

Our results are similar to that of \citet{ram2009}, but those results depend on
a quantity called the {\it constant of bichromaticity}, denoted $\kappa$, which
has unclear relation to cover tree imbalance.  The dependence on $\kappa$ is
given as $c_q^{4 \kappa}$, which is not a good bound, especially because
$\kappa$ may easily be very large.  Further, it is incorrectly claimed that
$\kappa = 1$ in the monochromatic case.

The more recent results of \citet{curtin2014dual} are more related to these
results, but they depend on the {\it inverse constant of bichromaticity} $\nu$
which suffers from the same problem as $\kappa$.  Although the dependence on
$\nu$ is linear (that is, $O(\nu N)$), bounding $\nu$ is difficult and it is not
true that $\nu = 1$ in the monochromatic case.

Both $\nu$ and $\kappa$ are difficult to empirically calculate and require an
entire run of the dual-tree algorithm.  On the other hand, bounding
$i_t(\mathscr{T}_q)$ (and $\theta$) can be done in one pass of the tree
(assuming the tree is already built).  Thus, not only is our bound tighter, it
more closely reflects the actual behavior of dual-tree algorithms, and the
constants which it depends upon are straightforward to calculate.

In the following sections, we will apply our results to specific problems and
show the utility of our bound in simplifying runtime proofs for dual-tree
algorithms.

% This discussion already happened earlier... sort of.
%The expansion constant is related to a notion of intrinsic dimensionality of a
%dataset (as discussed earlier). A relatively small $c_r$ corresponds to
%a dataset with low intrinsic dimensionality, while a value of $c_r$ independent
%of $N$ implies that the intrinsic dimensionality of the data is independent of
%the number of points in the dataset. The latter is a reasonable assumption in
%many scenarios.
%Our bound has a linear dependence on the inverse constant of bichromaticity
%$\nu$; this results from the worst-case situation where the reference tree is
%recursed entirely after all query tree recursions
% this makes sense, given that $\nu$ represents the maximum number of times
%any set $R$ is descended for any query node $\mathscr{N}_q$ before
%$\mathscr{N}_q$ is recursed.


% Space constraints :(

%The runtime bound $\chi$ for the \texttt{BaseCase($p_q$, $p_r$)} function
%corresponds to the time required to process a pair of points. For example, in
%range search, \texttt{BaseCase()} corresponds to the
%time taken to compute $d(p_q, p_r)$ and determine if that falls into the desired
%range.  For general kernel summations, this corresponds to computing the
%pairwise kernel function between $p_q$ and $p_r$ and then summing it to the
%output for $p_q$.  In general, the runtime of \texttt{BaseCase()} is dominated
%by the pairwise function computation which is independent of $N$ and is usually
%$O(1)$. The \texttt{Score()} function is an operation on a pair of nodes and
%usually involves computing a bound which requires a pairwise function
%computation between the node centers (similar to the \texttt{BaseCase()}
%function except that it is for node centres) and certain cached node statistics
%(such as node radius in the metric space). Hence its runtime bound $\psi$ is
%usually a constant independent of $N$ or simply $O(1)$.
