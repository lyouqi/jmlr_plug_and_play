Perhaps more interesting than measures of tree imbalance is the way cover trees
are actually used in dual-tree algorithms.  Although cover trees were originally
intended for nearest neighbor search \citep[See Algorithm
\texttt{Find-All-Nearest},][]{langford2006}, they can be adapted to a wide
variety of problems: minimum
spanning tree calculation \citep{march2010euclidean}, approximate nearest neighbor
search \citep{ram2009rank}, Gaussian processes posterior calculation
\citep{moore2014fast}, and max-kernel search \citep{curtin2014dual} are some
examples.  Further, through the tree-independent dual-tree algorithm abstraction
of \citet{curtin2013tree}, other existing dual-tree algorithms can easily be
adapted for use with cover trees.

In the framework of tree-independent dual-tree algorithms, all that is necessary
to describe a dual-tree algorithm is a point-to-point base case function
(\texttt{BaseCase()}) and a node-to-node pruning rule (\texttt{Score()}).  These
functions, which are often very straightforward, are then paired with a type of
tree and a pruning dual-tree traversal to produce a working algorithm.  In later
sections, we will consider specific examples.

\begin{algorithm}[tb]
  \begin{algorithmic}[1]
    \STATE {\bfseries Input:} query node $\mathscr{N}_q$, set of reference nodes
$R$ \label{alg:line:ct-dual-input}
    \STATE {\bfseries Output:} none

    \medskip
    \STATE $s^{\max}_r \gets \max_{\mathscr{N}_r \in R} s_r$
\label{alg:line:ct-dual-srmax}
    \IF{$(s_q < s^{\max}_r)$} \label{alg:line:ct-dual-ref-recursion-start}
      \STATE \COMMENT{Perform a reference recursion.}
      \FORALL{$\mathscr{N}_r \in R$} \label{alg:line:ct-dual-base-case-start}
        \STATE \texttt{BaseCase($p_q$, $p_r$)}
      \ENDFOR \label{alg:line:ct-dual-base-case-end}
      \STATE $R_r \gets \{ \mathscr{N}_r \in R : s_r = s^{\max}_r \}$
\label{alg:line:ct-dual-ref-set}
      \STATE $R_{r - 1} \gets \{ \mathscr{C}(\mathscr{N}_r) : \mathscr{N}_r \in
R_r \} \cup (R \setminus R_r)$ \label{alg:line:ct-dual-ref-children}
      \STATE $R'_{r - 1} \gets \{ \mathscr{N}_r \in R_{r - 1} :
\texttt{Score(}\mathscr{N}_q\texttt{,} \mathscr{N}_r\texttt{)} \ne \infty \}$
\label{alg:line:ct-dual-ref-score}
      \STATE recurse with $\mathscr{N}_q$ and $R'_{r - 1}$
\label{alg:line:ct-dual-ref-recursion-end}
    \ELSE \label{alg:line:ct-dual-query-recursion-start}
      \STATE \COMMENT{Perform a query recursion.}
      \FORALL{$\mathscr{N}_{qc} \in \mathscr{C}(\mathscr{N}_q)$}
        \STATE $R' \gets \{ \mathscr{N}_r \in R :
\texttt{Score(}\mathscr{N}_q\texttt{,} \mathscr{N}_r\texttt{)} \ne \infty \}$
\label{alg:line:ct-dual-query-pruning}
        \STATE recurse with $\mathscr{N}_{qc}$ and $R'$
\label{alg:line:ct-dual-query-recursion}
      \ENDFOR \label{alg:line:ct-dual-query-recursion-end}
    \ENDIF
  \end{algorithmic}
  \caption{The standard pruning dual-tree traversal for cover trees.}
  \label{alg:cover-tree-dual}
\end{algorithm}

When using cover trees, the typical pruning dual-tree traversal is an adapted
form of the original nearest neighbor search algorithm \citep[see
\texttt{Find-All-Nearest},][]{langford2006}; this traversal is implemented in
both the cover tree reference implementation and in the more flexible {\bf
mlpack} library \citep{mlpack2013}.  The problem-independent traversal is given
in Algorithm \ref{alg:cover-tree-dual} and was originally presented by
\citet{curtin2014dual}.  Initially, it is called with the root of the query tree
and a reference set $R$ containing only the root of the reference tree.

This dual-tree recursion is a depth-first recursion in the query tree and a
breadth-first recursion in the reference tree; to this end, the recursion
maintains one query node $\mathscr{N}_q$ and a reference set $R$.  The set $R$
may contain reference nodes with many different scales; the maximum scale in the
reference set is $s_r^{\max}$ (line \ref{alg:line:ct-dual-srmax}).  Each single
recursion will descend either the query tree or the reference tree, not both;
the conditional in line \ref{alg:line:ct-dual-ref-recursion-start}, which
determines whether the query or reference tree will be recursed, is aimed at
keeping the relative scales of query nodes and reference nodes close.

A query recursion (lines
\ref{alg:line:ct-dual-query-recursion-start}--\ref{alg:line:ct-dual-query-recursion-end})
is straightforward: for each child $\mathscr{N}_{qc}$ of $\mathscr{N}_q$, the
node combinations $(\mathscr{N}_{qc}, \mathscr{N}_r)$ are scored for each
$\mathscr{N}_r$ in the reference set $R$.  If possible, these combinations are
pruned to form the set $R'$ (line \ref{alg:line:ct-dual-query-recursion}) by
checking the output of the \texttt{Score()} function, and then the algorithm
recurses with $\mathscr{N}_{qc}$ and $R'$.

A reference recursion (lines
\ref{alg:line:ct-dual-ref-recursion-start}--\ref{alg:line:ct-dual-ref-recursion-end})
is similar to a query recursion, but the pruning strategy is significantly more
complicated.  Given $R$, we calculate $R_r$, which is the set of nodes in $R$
that have scale $s_r^{\max}$.  Then, for each node $\mathscr{N}_r$ in the set of
children of nodes in $R_r$, the node combinations $(\mathscr{N}_q,
\mathscr{N}_r)$ are scored and pruned if possible.  Those reference nodes that
were not pruned form the set $R'_{r - 1}$.  Then, this set is combined with $R
\setminus R_r$---that is, each of the nodes in $R$ that was {\em not} recursed
into---to produce $R'$, and the algorithm recurses with $\mathscr{N}_q$ and the
reference set $R'$.

The reference recursion only recurses into the top-level subset of the reference
nodes in order to preserve the separation invariant.  It is easy to show that
every pair of points held in nodes in $R$ is separated by at least
$2^{s_r^{\max}}$:

\begin{lemma}
For all nodes $\mathscr{N}_i, \mathscr{N}_j \in R$ (in the context of Algorithm
\ref{alg:cover-tree-dual}) which contain points $p_i$ and $p_j$, respectively,
$d(p_i, p_j) > 2^{s_r^{\max}}$, with $s_r^{\max}$ defined as in line
\ref{alg:line:ct-dual-srmax}.
\end{lemma}

\begin{proof}
This proof is by induction.  If $|R| = 1$, such as during the first reference
recursion, the result obviously holds.  Now consider any reference set $R$ and
assume the statement of the lemma holds for this set $R$, and define
$s_r^{\max}$ as the maximum scale of any node in $R$.  Construct the set
$R_{r - 1}$ as in line \ref{alg:line:ct-dual-ref-children} of Algorithm
\ref{alg:cover-tree-dual}; if $| R_{r - 1} | \le 1$, then $R_{r - 1}$ satisfies
the desired property.

Otherwise, take any $\mathscr{N}_i, \mathscr{N}_j$ in $R_{r - 1}$, with points
$p_i$ and $p_j$, respectively, and scales $s_i$ and $s_j$, respectively.
Clearly, if $s_i = s_j = s_r^{\max} - 1$, then by the separation invariant
$d(p_i, p_j) > 2^{s_r^{\max} - 1}$.

Now suppose that $s_i < s_r^{\max} - 1$.  This implies that there exists some
implicit cover tree node with point $p_i$ and scale $s_r^{\max} - 1$ (as well an
implicit child of this node $p_i$ with scale $s_r^{\max} - 2$ and so forth until
one of these implicit nodes has child $p_i$ with scale $s_i$).  Because the
separation invariant applies to both implicit and explicit representations of
the tree, we conclude that $d(p_i, p_r) > 2^{s_r^{\max}} - 1$.  The same
argument may be made for the case where $s_j < s_r^{\max} - 1$, with the same
conclusion.

We may therefore conclude that each point of each node in $R_{r - 1}$ is
separated by $2^{s_r^{\max} - 1}$.  Note that $R'_{r - 1} \subseteq R_{r - 1}$
and that $R \setminus R_{r - 1} \subseteq R$ in order to see that this condition
holds for all nodes in $R' = R'_{r - 1} \cup (R \setminus R_{r - 1})$.

Because we have shown that the condition holds for the initial reference set and
for any reference set produced by a reference recursion, we have shown that the
statement of the lemma is true.
\end{proof}

This observation means that the set of points $P$ held by all nodes in $R$ is
always a subset of $C_{s_r^{\max}}$.  This fact will be useful in our later
runtime proofs.

Next, we develop notions with which to understand the behavior of the cover tree
dual-tree traversal when the datasets are of significantly different scale
distributions.

If the datasets are similar in scale distribution (that is, inter-point distances
tend to follow the same distribution), then the recursion will alternate between
query recursions and reference recursions.  But if the query set contains points
which are, in general, much farther apart than the reference set, then the
recursion will start with many query recursions before reaching a reference
recursion.  The converse case also holds.  We are interested in formalizing
this notion of scale distribution; therefore, define the following
dataset-dependent constants for the query set $S_q$ and the reference set $S_r$:

\begin{itemize}
  \item $\eta_q$: the largest pairwise distance in $S_q$
  \item $\delta_q$: the smallest nonzero pairwise distance in $S_q$
  \item $\eta_r$: the largest pairwise distance in $S_r$
  \item $\delta_r$: the smallest nonzero pairwise distance in $S_r$
\end{itemize}

These constants are directly related to the aspect ratio of the datasets;
indeed, $\eta_q / \delta_q$ is exactly the aspect ratio of $S_q$.  Further,
let us define and bound the top and bottom levels of each tree:

\begin{itemize}
  \item The {\it top scale} $s_q^T$ of the query tree $\mathscr{T}_q$ is such
that as $\lceil \log_2(\eta_q) \rceil - 1 \le s_q^T \le \lceil \log_2(\eta_q)
\rceil$.
  \item The {\it minimum scale} of the query tree $\mathscr{T}_r$ is defined as
$s_q^{\min} = \lceil \log_2(\delta_q) \rceil$.
  \item The top scale $s_r^T$ of the reference tree $\mathscr{T}_r$ is such that
as $\lceil \log_2(\eta_r) \rceil - 1 \le s_r^T \le \lceil \log_2(\eta_r)
\rceil$.
  \item The minimum scale of the reference tree $\mathscr{T}_r$ is defined as
$s_r^{\min} = \lceil \log_2(\delta_r) \rceil$.
\end{itemize}

Note that the minimum scale is not the minimum scale of {\it any} cover tree
node (that would be $-\infty$), but the minimum scale of any non-leaf node in
the tree.

Suppose that our datasets are of a similar scale distribution: $s_q^T = s_r^T$,
and $s_q^{\min} = s_r^{\min}$.  In this setting we will have alternating query
and reference recursions.  But if this is not the case, then we have extra
reference recursions before the first query recursion or after the last query
recursion (situations where both these cases happen are possible).  Motivated by
this observation, let us quantify these extra reference recursions:

\begin{lemma}
\label{lem:extcase1}
For a dual-tree algorithm with $|S_q| \sim |S_r| \sim O(N)$ using cover trees and
the traversal given in Algorithm \ref{alg:cover-tree-dual}, the number of extra
reference recursions that happen before the first query recursion is bounded by

\begin{equation}
\min\left(O(N), \log_2(\eta_r / \eta_q) - 1\right).
\end{equation}
\end{lemma}

\begin{proof}
The first query recursion happens once $s_q \ge s_r^{\max}$.  The number of
reference recursions before the first query recursion is then bounded as the
number of levels in the reference tree between $s_r^T$ and $s_q^T$ that have at
least one explicit node.  Because there are $O(N)$ nodes in the reference tree,
the number of levels cannot be greater than $O(N)$ and thus the result holds.

The second bound holds by applying the definitions of $s_r^T$ and $s_q^T$ to the
expression $s_r^T - s_q^T - 1$:

\begin{eqnarray}
s_r^T - s_q^T - 1 &\le& \lceil \log_2(\eta_r) \rceil - (\lceil \log_2(\eta_q)
\rceil - 1) - 1 \\
&\le& \log_2(\eta_r) + 1 - \log_2(\eta_q)
\end{eqnarray}

\noindent which gives the statement of the lemma after applying logarithmic
identities.
\end{proof}

Note that the $O(N)$ bound may be somewhat loose, but it suffices for our later
purposes.  Now let us consider the other case:

\begin{lemma}
\label{lem:extcase3}
For a dual-tree algorithm with $|S_q| \sim |S_r| \sim O(N)$ using cover trees and
the traversal given in Algorithm \ref{alg:cover-tree-dual}, the number of extra
reference recursions that happen after the last query recursion is bounded by

\begin{equation}
\max\left\{\min\left[O(N \log_2(\delta_q / \delta_r)),
O(N^2)\right], \; 0\right\}.
\end{equation}
\end{lemma}

For convenience, we define a term that encapsulates this bound.

\begin{defn}
Define $\theta$ as a bound on the number of extra reference recursions tha
happen after the last query recursion.  Then,

\begin{equation}
\theta = \max\left\{\min\left[O(N \log_2(\delta_q / \delta_r)), O(N^2)\right],
\; 0\right\}.
\end{equation}
\end{defn}

\begin{proof}
Our goal here is to count the number of reference recursions after the final
query recursion at level $s_q^{\min}$; the first of these reference recursions
is at scale $s_r^{\max} = s_q^{\min}$.  Because query nodes are not pruned in
this traversal, each reference recursion we are counting will be duplicated over
the whole set of $O(N)$ query nodes.  The first part of the bound follows by
observing that
$s_q^{\min} - s_r^{\min} \le \lceil \log_2(\delta_q) \rceil -
\lceil \log_2(\delta_r) \rceil - 1 \le \log_2(\delta_q / \delta_r)$.

The second part follows by simply observing that there are $O(N)$ reference
nodes.
\end{proof}

These two previous lemmas allow us a better understanding of what happens as the
reference set and query set become different.  Lemma \ref{lem:extcase1} shows
that the number of extra recursions caused by a reference set with larger
pairwise distances than the query set ($\eta_r$ larger than $\eta_q$) is modest;
on the other hand, Lemma \ref{lem:extcase3} shows that for each extra level in
the reference tree below $s_q^{\min}$, $O(N)$ extra recursions are required.
Using these lemmas and this intuition, we will prove general runtime bounds for
the cover tree traversal.

\begin{thm}
\label{thm:ct-runtime}
%For any dual-tree algorithm using cover trees and the standard cover tree
%dual-tree pruning traversal (Algorithm \ref{alg:cover-tree-dual}) with reference
%set $S_r$ that has expansion constant $c_r$ and query set $S_q$, the runtime is
%bounded above by $O(c_r^4 | R^* | \nu \chi \psi N)$, where $ | R^* | $ is
%the maximum size of the reference set $R$ (line
%\ref{alg:line:ct-dual-input}) at any point in the dual-tree pruning traversal,
%$\chi$ is the longest possible running time of \texttt{BaseCase()}, and $\psi$
%is the longest possible running time of \texttt{Score()}.
Given a reference set $S_r$ of size $O(N)$ with an expansion constant $c_r$ and a
set of queries $S_q$ of size $O(N)$, a standard cover tree based dual-tree
algorithm (Algorithm \ref{alg:cover-tree-dual}) takes

\begin{equation}
O\left(c_r^4 | R^* | \chi \psi (N + I_t(\mathscr{T}_q) + \theta)\right)
\end{equation}

\noindent time, where $ | R^* | $ is the maximum size of the reference set $R$
(line \ref{alg:line:ct-dual-input}) during the dual-tree recursion, $\chi$ is
the maximum possible runtime of \texttt{BaseCase()}, $\psi$ is the maximum
possible runtime of \texttt{Score()}, and $\theta$ is defined as in Lemma
\ref{lem:extcase3}.
\end{thm}

\begin{proof}
First, split the algorithm into two parts: reference recursions (lines
\ref{alg:line:ct-dual-ref-recursion-start}--\ref{alg:line:ct-dual-ref-recursion-end})
and query recursions (lines
\ref{alg:line:ct-dual-query-recursion-start}--\ref{alg:line:ct-dual-query-recursion-end}).
The runtime of the algorithm is bounded as the runtime of a reference recursion
times the total number of reference recursions plus the total runtime of all
query recursions.

Consider a reference recursion (lines
\ref{alg:line:ct-dual-ref-recursion-start}--\ref{alg:line:ct-dual-ref-recursion-end}).
Define $R^*$ to be the largest set $R$ for any scale
$s_r^{\max}$ and any query node $\mathscr{N}_q$ during the course of the
algorithm; then, it is true that $| R | \le | R^* |$.  The work done in the base
case loop from lines
\ref{alg:line:ct-dual-base-case-start}--\ref{alg:line:ct-dual-base-case-end} is
thus $O(\chi | R |) \le O(\chi | R^*|)$.
%
Then, lines \ref{alg:line:ct-dual-ref-children} and
\ref{alg:line:ct-dual-ref-score} take $O(c_r^4 \psi | R |) \le O(c_r^4 \psi |
R^* |)$ time, because each reference node has up to $c_r^4$ children.  So, one
full reference recursion takes $O(c_r^4 \psi \chi | R^* |)$ time.

Now, note that there are $O(N)$ nodes in $\mathscr{T}_q$.  Thus, line
\ref{alg:line:ct-dual-query-recursion} is visited $O(N)$ times.  The amount of
work in line \ref{alg:line:ct-dual-query-pruning}, like in the reference
recursion, is bounded as $O(c_r^4 \psi | R^* |)$. Therefore, the total runtime
of all query recursions is $O(c_r^4 \psi | R^* | N)$.

Lastly, we must bound the total number of reference recursions.  Reference
recursions happen in three cases: \textit{(1)} $s_r^{\max}$ is greater than the
scale of the root of the query tree (no query recursions have happened yet);
\textit{(2)} $s_r^{\max}$ is less than or equal to the scale of the root of the
query tree, but is greater than the minimum scale of the query tree that is not
$-\infty$; \textit{(3)} $s_r^{\max}$ is less than the minimum scale of the query
tree that is not $-\infty$.

First, consider case \textit{(1)}.  Lemma \ref{lem:extcase1} shows that the
number of reference recursions of this type is bounded by $O(N)$.  Although
there is also a bound that depends on the sizes of the datasets, we only aim to
show a linear runtime bound, so the $O(N)$ bound is sufficient here.

Next, consider case \textit{(2)}.  In this situation, each query recursion
implies at least one reference recursion before another query recursion.  For
some query node $\mathscr{N}_q$, the exact number of reference recursions before
the children of $\mathscr{N}_q$ are recursed into is bounded above by
$I_n(\mathscr{N}_q) + 1$: if $\mathscr{N}_q$ has imbalance $0$, then it is
exactly one level below its parent, and thus there is only one reference
recursion.  On the other hand, if $\mathscr{N}_q$ is many levels below its
parent, then it is possible that a reference recursion may occur for each level
in between; this is a maximum of $I_n(\mathscr{N}_q) + 1$.

Because each query node in $\mathscr{T}_q$ is recursed into once, the total
number of reference recursions before each query recursion is

\begin{equation}
\sum_{\mathscr{N}_q \in \mathscr{T}_q} I_n(\mathscr{N}_q) + 1 = I_t(\mathscr{T}_q) +
O(N)
\end{equation}

\noindent since there are $O(N)$ nodes in the query tree.

Lastly, for case \textit{(3)}, we may refer to Lemma \ref{lem:extcase3}, giving
a bound of $\theta$ reference recursions in this case.

We may now combine these results for the runtime of a query recursions with the
total number of reference recursions in order to give the result of the theorem:

\begin{equation}
O\left(c_r^4 |R^*| \psi \chi \left(N + I_t(\mathscr{T}_q) + \theta\right)\right)
+ O\left(c_r^4 |R^*| \psi N\right) \sim O\left(c_r^4 |R^*| \psi
\chi \left(N + I_t(\mathscr{T}_q) + \theta\right)\right).
\end{equation}
\end{proof}

When we consider the monochromatic case (where $S_q = S_r$)\footnote{In the
monochromatic case, we do not take a point as its own nearest neighbor, so
slight modification of {\tt BaseCase()} is necessary.  The runtime bound result
remains unchanged.}, the results trivially simplify.

\begin{cor}
\label{cor:ct-runtime-mono}
Given the situation of Theorem \ref{thm:ct-runtime} but with $S_q = S_r = S$ so
that $c_q = c_r = c$ and $\mathscr{T}_q = \mathscr{T}_r = \mathscr{T}$, a
dual-tree algorithm using the standard cover tree traversal (Algorithm
\ref{alg:cover-tree-dual}) takes

\begin{equation}
O\left(c^4 |R^*| \chi \psi \left(N + I_t(\mathscr{T})\right)\right)
\end{equation}

\noindent time, where $ | R^* | $ is the maximum size of the reference set $R$
(line \ref{alg:line:ct-dual-input}) during the dual-tree recursion, $\chi$ is
the maximum possible runtime of \texttt{BaseCase()}, and $\psi$ is the maximum
possible runtime of \texttt{Score()}.
\end{cor}

An intuitive understanding of these bounds is best achieved by first considering
the monochromatic case (this case arises, for instance, in all-nearest-neighbor
search).  The linear dependence on $N$ arises from the fact that all query nodes
must be visited.  The dependence on the reference tree, however, is encapsulated
by the term $c^4 |R^*|$, with $|R^*|$ being the maximum size of the reference
set $R$; this value must be derived for each specific problem.  The bad
performance of poorly-behaved datasets with large $c$ (or, in the worst case, $c
\sim N$) is then captured in both of those terms.  Poorly-behaved datasets may
also have a high cover tree imbalance $I_t(\mathscr{T})$; the linear dependence of
runtime on imbalance is thus sensible for well-behaved datasets.

The bichromatic case ($S_q \ne S_r$) is a slightly more complex result which
deserves a bit more attention.  The intuition for all terms except $\theta$
remain virtually the same.

The term $\theta$ captures the effect of query and reference datasets with
different widths, and has one unfortunate corner case: when $\delta_q > \eta_r$,
then the query tree must be entirely descended before any reference recursion.
This results in a bound of the form $O(N \log (\eta_r / \delta_r))$, or
$O(N^2)$ (See Lemma \ref{lem:extcase3}).  This is because the reference tree
must be descended individually for each query point.

The quantity $|R^*|$ bounds the amount of work that needs to be done for each
recursion. In the worst case, $|R^*|$ can be $N$. However,
dual-tree algorithms rely on branch-and-bound techniques to prune away
work (Lines \ref{alg:line:ct-dual-ref-score} and
\ref{alg:line:ct-dual-query-pruning} in Algorithm \ref{alg:cover-tree-dual}). A
small value of $|R^*|$ will imply that the algorithm is extremely successful in
pruning away work.  An (upper) bound on $|R^*|$ (and the algorithm's
success in pruning work) will depend on the problem and the data.  As we will
show, bounding $|R^*|$ is often possible. % In addition, we will also show that
For many dual-tree algorithms, $\chi \sim \psi \sim O(1)$; often, cached
sufficient statistics \citep{moore2000anchors} can enable $O(1)$ runtime
implementations of \texttt{BaseCase()} and \texttt{Score()}.

These results hold for any dual-tree algorithm regardless of the problem. Hence,
%for any pairwise statistical problem, the runtime of the dual-tree algorithm (of
the runtime of any dual-tree algorithm
%that problem)
would be at least $O(N)$ using our bound, which matches the intuition that
answering $O(N)$ queries would take at least $O(N)$ time. For a particular
problem and data, if $c_r$, $|R^*|$, $\chi$, $\psi$ are bounded by constants
independent of $N$ and $\theta$ is no more than linear in $N$ (for large enough
$N$), then the dual-tree algorithm for that problem has a runtime linear in $N$.
Our theoretical result separates out the problem-dependent and the
problem-independent elements of the runtime bound, which allows us to simply
plug in the problem-dependent bounds in order to get runtime bounds for any
dual-tree algorithm without requiring an analysis from scratch.

Our results are similar to that of \citet{ram2009}, but those results depend on
a quantity called the {\it constant of bichromaticity}, denoted $\kappa$, which
has unclear relation to cover tree imbalance.  The dependence on $\kappa$ is
given as $c_q^{4 \kappa}$, which is not a good bound, especially because
$\kappa$ may be much greater than $1$ in the bichromatic case (where $S_q \ne
S_r$).

The more recent results of \citet{curtin2014dual} are more related to these
results, but they depend on the {\it inverse constant of bichromaticity} $\nu$
which suffers from the same problem as $\kappa$.  Although the dependence on
$\nu$ is linear (that is, $O(\nu N)$), bounding $\nu$ is difficult and it is not
true that $\nu = 1$ in the monochromatic case.

$\nu$ corresponds to the maximum number of reference recursions between a single
query recursion, and $\kappa$ corresponds to the maximum number of query
recursions between a single reference recursion.  The respective proofs that use
these constants then apply them as a worst-case measure for the whole algorithm:
when using $\kappa$, \citet{ram2009} assume that {\it every} reference recursion
may be followed by $\kappa$ query recursions; similarly, \citet{curtin2014dual}
assume that {\it every} query recursion may be followed by $\nu$ reference
recursions.  Here, we have simply used $I_t(\mathscr{T}_q)$ and $\theta$ as an
exact summation of the total extra reference recursions, which gives us a much
tighter bound than $\nu$ or $\kappa$ on the running time of the whole algorithm.

Further, both $\nu$ and $\kappa$ are difficult to empirically calculate and
require an entire run of the dual-tree algorithm.  On the other hand, bounding
$I_t(\mathscr{T}_q)$ (and $\theta$) can be done in one pass of the tree
(assuming the tree is already built).  Thus, not only is our bound tighter when
the cover tree imbalance is sublinear in $N$, it more closely reflects the
actual behavior of dual-tree algorithms, and the constants which it depends upon
are straightforward to calculate.

In the following sections, we will apply our results to specific problems and
show the utility of our bound in simplifying runtime proofs for dual-tree
algorithms.

% This discussion already happened earlier... sort of.
%The expansion constant is related to a notion of intrinsic dimensionality of a
%dataset (as discussed earlier). A relatively small $c_r$ corresponds to
%a dataset with low intrinsic dimensionality, while a value of $c_r$ independent
%of $N$ implies that the intrinsic dimensionality of the data is independent of
%the number of points in the dataset. The latter is a reasonable assumption in
%many scenarios.
%Our bound has a linear dependence on the inverse constant of bichromaticity
%$\nu$; this results from the worst-case situation where the reference tree is
%recursed entirely after all query tree recursions
% this makes sense, given that $\nu$ represents the maximum number of times
%any set $R$ is descended for any query node $\mathscr{N}_q$ before
%$\mathscr{N}_q$ is recursed.


% Space constraints :(

%The runtime bound $\chi$ for the \texttt{BaseCase($p_q$, $p_r$)} function
%corresponds to the time required to process a pair of points. For example, in
%range search, \texttt{BaseCase()} corresponds to the
%time taken to compute $d(p_q, p_r)$ and determine if that falls into the desired
%range.  For general kernel summations, this corresponds to computing the
%pairwise kernel function between $p_q$ and $p_r$ and then summing it to the
%output for $p_q$.  In general, the runtime of \texttt{BaseCase()} is dominated
%by the pairwise function computation which is independent of $N$ and is usually
%$O(1)$. The \texttt{Score()} function is an operation on a pair of nodes and
%usually involves computing a bound which requires a pairwise function
%computation between the node centers (similar to the \texttt{BaseCase()}
%function except that it is for node centres) and certain cached node statistics
%(such as node radius in the metric space). Hence its runtime bound $\psi$ is
%usually a constant independent of $N$ or simply $O(1)$.
